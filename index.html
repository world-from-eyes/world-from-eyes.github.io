<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Seeing the World through Your Eyes</title>
    <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PX8EQ0GVXW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-PX8EQ0GVXW');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Seeing the World through Your Eyes</span></h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://hadizayer.github.io">Hadi Alzayer*</a>&nbsp;&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block">
              <a href="https://www.kevinwzhang.com">Kevin Zhang*</a>&nbsp;&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block">
               <a href="https://brandonyfeng.github.io">Brandon Y. Feng</a>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
               <a href="https://www.cs.umd.edu/~metzler/">Christopher Metzler</a>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://jbhuang0604.github.io">Jia-Bin Huang</a>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
          </div>

          <div class="is-size-5 publication-authors">

            <span class="author-block">University of Maryland</span>
            <!-- <span class="author-block"><sup></span> -->
          </div>

          <span class="link-block">
          <!-- arxiv Link add TODO. -->
          <a href="https://arxiv.org/abs/2306.09348"
             class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="ai ai-arxiv"></i>
                  <path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                  </path>
                </svg>
            </span>
            <span>arXiv</span>
          </a>

          <a href=""
          class="external-link button is-normal is-rounded is-dark">
         <span class="icon">
             <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg="">
               <path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
               </path>
             </svg>
         </span>
         <span>Code (coming soon)</span>
       </a>

        </span>
      </div>
      </div>
    </div>
  </div>


</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <h2 class="title is-4">Results on single-camera scenes</h2> -->

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-kirby_dog">
          <video poster="" id="kirby_dog" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/kirby.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-alien">
          <video poster="" id="alien" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/plushies.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dog_plant">
          <video poster="" id="dog_plant" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dog.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-outdoor">
          <video poster="" id="outdoor" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/outdoor.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-poster">
          <video poster="" id="poster" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/poster.mp4"
                    type="video/mp4">
          </video>
        </div>        
      </div>
      <h3>
        <center>
        From a handful of portrait photos of a person, we compute a 3D reconstruction of what they are observing using the eye reflections!
      </center>
    </h3>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <h2 class="title is-4">Results on single-camera scenes</h2> -->

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-classroom">
          <video poster="" id="classroom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/classroom.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-kitchen">
          <video poster="" id="kitchen" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/kitchen.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-living_room">
          <video poster="" id="living_room" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/living_room.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-barbershop">
          <video poster="" id="barbershop" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/barbershop_flip.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-barbershopback">
          <video poster="" id="barbershopback" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/barbershop_interior.mp4"
                    type="video/mp4">
          </video>
        </div>
        
      </div>
      <h3>
        <center>
        By placing realistic eye models in synthetic scenes, we perform full scene reconstruction using only the eye reflections. 
      </center>
    </h3>
    </div>
  </div>
</section>

<!-- Abstract. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      The reflective nature of the human eye is an underappreciated source of information about what the world around us looks like. 
By imaging the eyes of a moving person, we can collect multiple views of a scene outside the camera's direct line-of-sight through the reflections in the eyes. In this paper,
we reconstruct a 3D scene beyond the camera's line-of-sight using portrait images containing eye reflections. <br>
This task is challenging due to <b>1)</b> the difficulty of accurately estimating eye pose and <b>2)</b> the entangled texture of the eye iris and the scene reflections.
Our method jointly refines the cornea poses, the radiance field depicting the scene, and the observer's eye iris texture. We further propose a simple regularization prior on the iris texture pattern to improve reconstruction quality. 
Through various experiments on synthetic and real-world captures featuring people with varied eye colors, we demonstrate the feasibility of our approach to recover 3D scenes using eye reflections.
    </div>
  </div>
</div>

<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">How we did it?</h2>
    <div class="content has-text-justified">

      The cornea geometry is approximately the same across all healthy adults. Because of this fact, if we count the pixel size of a person's cornea in the image, we can compute exactly where their eyes are.  Using this insight, we train the radiance field on the eye reflections by shooting rays from the camera, and reflecting them off the approximated eye geometry. To remove the iris from showing up in the reconstruction, we perform <b> texture decomposition </b> by simultaneously training a 2D texture map that learns the iris texture.

      <center>
        <img src="./static/images/rf-eyes-overview-figure-arrow.png">
      </center>
      However, approximating the eye pose just from the image is always very noisy. To address this issue, we perform <b>eye pose optimization</b> which is critical for performance as we show below.
    </div>
  </div>
</div>

<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Eye pose optimization ablation</h2>
    <div class="content has-text-justified">

      <!-- <label class="label" id="example2_deblurring_w" style="width: 49%; vertical-align: middle;margin: 0; padding: 0;">
      <video poster="" id="no_pose" autoplay controls muted loop playsinline>
        <source src="./static/videos/lit_plushies_spiral_no_pose.mp4"
                type="video/mp4">
      </video>
      </label>
      <label class="label" id="example2_deblurring_w" style="width: 48%; vertical-align: middle;margin: 0; padding: 0;">
      <video poster="" id="no_pose" autoplay controls muted loop playsinline>
        <source src="./static/videos/lit_plushies_spiral.mp4"
                type="video/mp4">
      </video>
      </label> -->
      <div style="display: flex;">
        <div style="width: 48%; text-align: center;">
          <video poster="" id="no_pose" autoplay controls muted loop playsinline>
            <source src="./static/videos/ablation/lit_plushies_no_pose.mp4" type="video/mp4">
          </video>
          <p style="margin: 0;">Without pose optimization</p>
        </div>
        <div style="width: 4%;">
        </div>
        <div style="width: 48%; text-align: center;">
          <video poster="" id="pose" autoplay controls muted loop playsinline>
            <source src="./static/videos/ablation/lit_plushies_with_pose.mp4" type="video/mp4">
          </video>
          <p style="margin: 0;">With pose optimization</p>
        </div>
      </div>
      
    </div>
  </div>
</div>

<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Texture decomposition ablation</h2>
    <div class="content has-text-justified">

      <div style="display: flex;">
        <div style="width: 48%; text-align: center;">
          <video poster="" id="no_texture" autoplay controls muted loop playsinline>
            <source src="./static/videos/ablation/ukulele_no_texture.mp4" type="video/mp4">
          </video>
          <p style="margin: 0;">Without texture decomposition</p>
        </div>
        <div style="width: 4%;">
        </div>
        <div style="width: 48%; text-align: center;">
          <video poster="" id="tex" autoplay controls muted loop playsinline>
            <source src="./static/videos/ablation/ukulele_with_texture.mp4" type="video/mp4">
          </video>
          <p style="margin: 0;">With texture decomposition</p>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Failure cases</h2>
    <div class="content has-text-justified">

      <!-- <label class="label" id="example2_deblurring_w" style="width: 49%; vertical-align: middle;margin: 0; padding: 0;">
      <video poster="" id="no_pose" autoplay controls muted loop playsinline>
        <source src="./static/videos/lit_plushies_spiral_no_pose.mp4"
                type="video/mp4">
      </video>
      </label>
      <label class="label" id="example2_deblurring_w" style="width: 48%; vertical-align: middle;margin: 0; padding: 0;">
      <video poster="" id="no_pose" autoplay controls muted loop playsinline>
        <source src="./static/videos/lit_plushies_spiral.mp4"
                type="video/mp4">
      </video>
      </label> -->
      <div style="display: flex;">
        <div style="width: 48%; text-align: center;">
          <video poster="" id="no_pose" autoplay controls muted loop playsinline>
            <source src="./static/videos/failed_1.mp4" type="video/mp4">
          </video>
        </div>
        <div style="width: 4%;">
        </div>
        <div style="width: 48%; text-align: center;">
          <video poster="" id="pose" autoplay controls muted loop playsinline>
            <source src="./static/videos/failed_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <p>When only small number of images used (4 or less) or if the motion is too small. The method can fail in reconstructing the geometry or include holes and missing regions in the reconstruction</p>
    </div>
  </div>
</div>

<!--/ Abstract. -->
<!-- 
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4">Results on single-camera scenes</h2>

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_chair.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_ship.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_drums.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_lego.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_ficus.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_hotdog.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_materials.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_mic.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_yujia.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/p_law.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <p>
        We also deploy our method on multi-camera captures, including 8 synthetic scenes generated with Blender,
         and 2 real-world scenes focused on human captures. 
         We perform more analysis using the Blender scenes where ground truth can be generated.
      </p>
    </div>
  </div>
</section>

<div class="hero-body">
  <div class="container">
    <h2 class="title is-4"><b>Stablization from handheld captures</b></h2>
  </div>
  <br>
  <div class="container is-max-desktop">
    <div class="content" align="center">
      <video autoplay muted loop playsinline controls width="80%">
        <source src="./static/videos/2DCompare.mp4"
            type="video/mp4">
      </video>
      <p>
        Prior 2D method (phase-based Eulerian) fails on a handheld-captured video with camera shake as it assumes stablized or tripod capture.
        Our method benefits from having a 3D representation and successfully separates camear motion from scene motion.
      </p>
    </div>
  </div>
</div>

<div class="hero-body">
  <div class="container">
      <h2 class="title is-4"><b>Remapping to handheld poses</b></h2>
  </div>
  <br>
  <div class="container is-max-desktop">
    <div class="content" align="center">
      <video autoplay muted loop playsinline controls width="80%">
        <source src="./static/videos/TrackedPose.mp4"
            type="video/mp4">
      </video>
      <p>
        We provide motion-magnified rendering at <b><i>Tracked Poses</i></b>, which are estimated from the 
        <br>shaky handheld capture, 
        and <b><i>Fixed Pose</i></b>, which is a static viewpoint.
      </p>
    </div>
  </div>
</div>

<div class="hero-body">
  <div class="container">
    <h2 class="title is-4"><b>Frequency selection</b></h2>
  </div>
  <br>
  <div class="container is-max-desktop">
    <div class="content" align="center">
      <video autoplay muted loop playsinline controls width="80%">
        <source src="./static/videos/fork2.mp4"
            type="video/mp4">
      </video>
      <p>
        We capture two tuning forks with different vibration frequnecies (Left: 64 Hz, Right: 128 Hz). <br>
        By temporally filtering the point embeddings, we can selectively amplify different frequencies.
      </p>
    </div>
  </div>
</div>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4">Comparisons of different magnification strategies</h2>
    </div>
  </div>

  <div class="hero-body">
    <div class="container">
      <h4 class="is-4" align="center"><b>Using Positional Encoding as Point Embedding Function</b></h4>
    </div>
  </div>
  <div class="container is-max-desktop">    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified" align="center">
          <video id="teaser" autoplay muted loop playsinline controls width="99%">
        <source src="./static/videos/false_motion.mp4"
                type="video/mp4">
      </video>
          <p>
            <b><i>Position Shift</i></b> predicts a 3D displacement for the input point before positional encoding, while
            <b><i>Encoding Shift</i></b> predicts a phase shift within each sine wave for the input point during positional encoding.
            We perform Linear Eulerian magnification by amplifying the temporal variations of the predicted shifts.
            <b><i>Position Shift</i></b> leads to false motions, while <b><i>Encoding Shift</i></b> reduces such artifacts.
          </p>
        </div>
      </div>
    </div>
  </div>
  <br>
  <div class="hero-body">
    <div class="container">
      <h4 class="is-4" align="center"><b>Using Tri-Plane as Point Embedding Function</b></h>
    </div>
  </div>
  <div class="container is-max-desktop">    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified" align="center">
          <video id="teaser" autoplay muted loop playsinline controls width="99%">
        <source src="./static/videos/clipped.mp4"
                type="video/mp4">
      </video>
          <p>
            <b><i>Linear - Tri-Plane</i></b> applies linear Eulerian magnification on tri-plane features.<br>
            <b><i>Phase - Tri-Plane</i></b> applies phase-based Eulerian magnification on tri-plane features.<br>
            <b><i>Linear - Tri-Plane</i></b> causes artifacts like clipped intensities, while <b><i>Phase - Tri-Plane</i></b> reduces such artifacts.
          </p>
          <br>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4">Varying the magnification factor</h2>
    </div>
  </div>

  <div class="container is-max-desktop">    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <video id="teaser" autoplay muted loop playsinline controls width="99%">
            <source src="./static/videos/varyalpha.mp4"
                type="video/mp4">
          </video>
          <p align="center">
            We visualize the impact of varying the magnification factor.
          </p>
        <br>
        </div>
      </div>
  
      </div>
  </div>
  <br>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4">Comparisons to video-based magnificatios</h2>

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-chair">
          <video poster="" id="hand" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-drums">
          <video poster="" id="train" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/drums.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-ficus">
          <video poster="" id="horsejump-low" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/ficus.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hotdog">
          <video poster="" id="kite-walk" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/hotdog.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-lego">
          <video poster="" id="kite-walk" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/lego.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-materials">
          <video poster="" id="kite-walk" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/materials.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mic">
          <video poster="" id="kite-walk" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mic.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-ship">
          <video poster="" id="kite-walk" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/ship.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <p align="left">
        <b><i>Observed</i></b> are Blender renderings from scenes with subtle object motions. 
        <b><i>Ground Truth</i></b>  are Blender renderings where the true object motions are artificially amplified. <br>
        <b><i>Linear - Video</i></b>  and <b><i>Phase - Video</i></b>  are obtained by deploying 2D magnification methods on the non-magnified RGB videos rendered by NeRF. 
        In general, 3D methods that perform magnification in the embedding space produce fewer artifacts compared to 2D methods.
        Furthermore, 2D methods requires rendering at a fixed viewpoint and, for every new rendering, re-running video magnification on the fly.
        In contrast, magnification on tri-planes is performed just once, and the motion-magnified tri-planes can then be used to render at new viewpoints.
     </p>
    </div>
    <br>
  </div>
</section> -->



<footer class="footer">
  <div align="center" class="container">
    <div class="columns is-centered">
        <div class="content">
            The website template is from <a href="https://nerfies.github.io/">Nerfies</a>.
        </div>
      </div>
    </div>
</footer>

</body>
</html>